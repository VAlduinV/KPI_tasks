{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Реалізація нейромережі із бібліотекою numpy\n",
    "Конструювання класу Backpropagation для побудови нейромережі із навчанням методом зворотнього поширення помилки. Застосовуємо множення векторів і матриць методами бібліотеки numpy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b5449a4f088dff8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Збільшимо кількість нейронів у прихованому шарі до 4.**\n",
    "- **Змінимо активаційну функцію у прихованому шарі на сигмоїд.**\n",
    "- **Змінимо метод навчання на стохастичний градієнтний спуск (SGD).**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6df53972bdd30e2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _path: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m seed, random\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmplcyberpunk\u001B[39;00m\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mstyle\u001B[38;5;241m.\u001B[39muse(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcyberpunk\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kpi-tasks-Qr_Mwa1g-py3.10\\lib\\site-packages\\matplotlib\\__init__.py:174\u001B[0m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse \u001B[38;5;28;01mas\u001B[39;00m parse_version\n\u001B[0;32m    172\u001B[0m \u001B[38;5;66;03m# cbook must import matplotlib only within function\u001B[39;00m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;66;03m# definitions, so it is safe to import from it here.\u001B[39;00m\n\u001B[1;32m--> 174\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m sanitize_sequence\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MatplotlibDeprecationWarning\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kpi-tasks-Qr_Mwa1g-py3.10\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, cbook\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ls_mapper\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolors\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Colormap, is_color_like\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_fontconfig_pattern\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m parse_fontconfig_pattern\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_enums\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JoinStyle, CapStyle\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kpi-tasks-Qr_Mwa1g-py3.10\\lib\\site-packages\\matplotlib\\colors.py:57\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m---> 57\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _cm, cbook, scale\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_color_data\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01m_ColorMapping\u001B[39;00m(\u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kpi-tasks-Qr_Mwa1g-py3.10\\lib\\site-packages\\matplotlib\\scale.py:22\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, _docstring\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mticker\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     23\u001B[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001B[0;32m     24\u001B[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001B[0;32m     25\u001B[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Transform, IdentityTransform\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mScaleBase\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kpi-tasks-Qr_Mwa1g-py3.10\\lib\\site-packages\\matplotlib\\ticker.py:143\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mmpl\u001B[39;00m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api, cbook\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m transforms \u001B[38;5;28;01mas\u001B[39;00m mtransforms\n\u001B[0;32m    145\u001B[0m _log \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger(\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m    147\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTickHelper\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFixedFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    148\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNullFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFuncFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFormatStrFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    149\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStrMethodFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mScalarFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLogFormatter\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    155\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMultipleLocator\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMaxNLocator\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAutoMinorLocator\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    156\u001B[0m            \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSymmetricalLogLocator\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAsinhLocator\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLogitLocator\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\kpi-tasks-Qr_Mwa1g-py3.10\\lib\\site-packages\\matplotlib\\transforms.py:49\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinalg\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m inv\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _api\n\u001B[1;32m---> 49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_path\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     50\u001B[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpath\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Path\n\u001B[0;32m     53\u001B[0m DEBUG \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing _path: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# підключення бібліотек\n",
    "import numpy as np\n",
    "from random import seed, random\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "\n",
    "plt.style.use(\"cyberpunk\")\n",
    "\n",
    "# множення вектора входу на матрицю вагів  - numpy\n",
    "A = np.array([1, 0, 0])\n",
    "B = [[1,0],[0,1],[1,0]]\n",
    "C = A @ B\n",
    "print(' Вхід\\n',A, '\\n ваги\\n',B, '\\n множимо:\\n',C)\n",
    "\n",
    "class Backpropagation:\n",
    "\n",
    "    coefs = []        # матриці вагових коефіцієнтів\n",
    "    neurons = []        # активність нейронів в нейромережі\n",
    "    errors = []         # розрахунок помилок в активності нейронів\n",
    "\n",
    "    # ініціалізація нейромережі із шарами нейронів\n",
    "    def __init__(self, nInputs, nHidden, nOutputs):\n",
    "        self.coefs.clear()\n",
    "        # hiddenLayer\n",
    "        self.coefs.append([[1,0],[0,1],[1,0]])\n",
    "        #self.coefs.append(0.3*np.random.rand(nInputs, nHidden))\n",
    "\n",
    "        # outputLayer\n",
    "        self.coefs.append([[1,1],[0,1]])\n",
    "        #self.coefs.append(0.3*np.random.rand(nHidden, nOutputs))\n",
    "\n",
    "\n",
    "    # активаційні функції нейрона\n",
    "\n",
    "    def activation(self, input):\n",
    "        return np.maximum(0, input)            # 'relu' - rectified linear unit\n",
    "\n",
    "    def sigmoid(self, input):\n",
    "        return 1.0 / (1.0 + np.exp(-input))    # 'logistic' сигмоїдна функція\n",
    "\n",
    "    def nielder(self, input):\n",
    "        t = (np.maximum(0.1,input)-0.19)/0.05\n",
    "        return 0.03*t/(0.26 + 0.04*t - 0.0001* t**2)   #  функція Нелдера\n",
    "\n",
    "    def leakyRelu(self, input):\n",
    "        res = input\n",
    "        res[input < -0.1] = -0.1\n",
    "        return res                              # 'leaky relu'\n",
    "\n",
    "\n",
    "    # розрахунок поширення активності по кільком шарам нейронів\n",
    "    def forwardPropagate(self, row):\n",
    "        inputs = row\n",
    "        self.neurons.clear()\n",
    "        self.neurons.append(inputs)\n",
    "\n",
    "        for layer in self.coefs:\n",
    "            s = inputs @ layer            # розрахунок прямого поширення активації із вагами  #inputs.dot(weights), numpy.matmul(inputs, layer)\n",
    "            inputs = self.activation(s)   # застосування активаційної функції до нейронів шару\n",
    "            self.neurons.append(inputs)\n",
    "        return inputs\n",
    "\n",
    "\n",
    "    # розрахунок помилки зворотнього поширення\n",
    "    def backwardPropagateError(self, expected):\n",
    "        self.errors.clear()\n",
    "        self.errors.append(expected - self.neurons[-1]) # запис різниці між виходом нейромережі і очікуваним\n",
    "        for i in reversed(range(len(self.coefs))):\n",
    "            layer = np.array(self.coefs[i])\n",
    "            self.errors.append( self.errors[-1] @ layer.T)   # множимо транспоновану матрицю вагів на останній елемент списку помилок\n",
    "        self.errors.reverse()\n",
    "\n",
    "    # навчання через зміну вагових коефіцієнтів\n",
    "    def updateWeights(self, learningRate):  #, row, nOutputs):\n",
    "        for i in range(len(self.coefs)):\n",
    "            self.coefs[i] += learningRate*np.outer(self.neurons[i], self.errors[i+1])\n",
    "\n",
    "    # процедура навчання по всій нейромережі\n",
    "    def Fit(self, train, labels, learningRate, max_iter, expectedError):\n",
    "        sumError = 10000.0\n",
    "        for epoch in range(max_iter):\n",
    "            if sumError <= expectedError:     # вихід з розрахунків, якщо малі похибки\n",
    "                print('навчання припинено через малі похибки')\n",
    "                break\n",
    "            sumError = 0\n",
    "            for  i in range(len(train)):\n",
    "                outputs = self.forwardPropagate(np.array(train[i]))\n",
    "                self.backwardPropagateError(labels[i])\n",
    "                sumError += np.sum(self.errors[-1]**2)\n",
    "                self.updateWeights(learningRate)\n",
    "            if epoch % 100 ==0:\n",
    "                print('Eпоха = %d,  сума квадратів помилок = %.3f' % (epoch, sumError))\n",
    "\n",
    "# ініціалізація нейромережі\n",
    "seed(1)\n",
    "NNet = Backpropagation( 3,     # кількість входів\n",
    "                        2,     # кількість нейронів в прихованому шарі\n",
    "                        2 )    # кількість нейронів в вихідному шарі\n",
    "\n",
    "x = np.linspace(-5,5,100)\n",
    "plt.plot(x, NNet.activation(x), 'r')\n",
    "\n",
    "x = np.linspace(-10,200,100)\n",
    "t = (np.maximum(20,x)-19.9)\n",
    "t1 = (np.maximum(10,x)-9.9)\n",
    "plt.plot(x, t/(0.26 + 0.04*t - 0.0001* t**2), 'r')\n",
    "plt.plot(x, t1/(0.26 + 0.04*t1 - 0.0001* t1**2), 'b')\n",
    "\n",
    "for layer in NNet.coefs:\n",
    "  print('шар \\n',layer)\n",
    "\n",
    "# тестуємо пряме поширення сигналів\n",
    "row = np.array([1, 0, 0])\n",
    "NNet.forwardPropagate(row)\n",
    "NNet.neurons\n",
    "\n",
    "# тестуємо розрахунок помилки\n",
    "NNet.backwardPropagateError([0,0])\n",
    "NNet.errors\n",
    "NNet.updateWeights(0.1)   # параметр швидкості навчання\n",
    "NNet.coefs\n",
    "\n",
    "# тестуємо навчання нейромережі\n",
    "max_iter = 2000\n",
    "learningRate = 0.01\n",
    "expectedError = 1e-3\n",
    "nOutput = 2\n",
    "\n",
    "trainingSet = [ [0, 0, 0],\n",
    "                [0, 0, 1],\n",
    "                [0, 1, 0],\n",
    "                [0, 1, 1],\n",
    "                [1, 0, 0],\n",
    "                [1, 0, 1],\n",
    "                [1, 1, 0],\n",
    "                [1, 1, 1] ]\n",
    "\n",
    "labelSet =   [ [ 1, 0],\n",
    "                [1, 0],\n",
    "                [1, 0],\n",
    "                [0, 0],\n",
    "                [0, 0],\n",
    "                [0, 1],\n",
    "                [0, 1],\n",
    "                [0, 1] ]\n",
    "\n",
    "NNet.Fit(trainingSet, labelSet, learningRate, max_iter, expectedError)\n",
    "\n",
    "# перевірка подібності цільових значень із розрахунками нейромоделі\n",
    "res = []\n",
    "for row in trainingSet:\n",
    "    res.append(NNet.forwardPropagate(row).round(1).tolist())\n",
    "print('\\nExpected =\\n  ', labelSet, '\\nResult = \\n', res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T14:33:42.439052400Z",
     "start_time": "2023-12-11T14:33:41.190233100Z"
    }
   },
   "id": "8ab661c6174c103b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ModifiedBackpropagation(Backpropagation):\n",
    "    # Зміни параметрів нейромережі\n",
    "    def __init__(self, nInputs, nHidden, nOutputs):\n",
    "        super().__init__(nInputs, nHidden, nOutputs)\n",
    "        # Зміна активаційної функції у прихованому шарі\n",
    "        self.coefs[0] = 0.3 * np.random.rand(nInputs, nHidden)\n",
    "        # Зміна кількості нейронів у прихованому шарі\n",
    "        self.coefs[1] = 0.3 * np.random.rand(nHidden, nOutputs)\n",
    "\n",
    "    def sigmoid(self, input):\n",
    "        return 1.0 / (1.0 + np.exp(-input))  # Сигмоїдна функція\n",
    "\n",
    "    # Модифікований метод навчання\n",
    "    def updateWeights(self, learningRate):\n",
    "        for i in range(len(self.coefs)):\n",
    "            # Зміна методу навчання на SGD\n",
    "            self.coefs[i] += learningRate * np.outer(self.neurons[i], self.errors[i + 1]) / len(self.neurons)\n",
    "\n",
    "# Ініціалізація модифікованої нейромережі\n",
    "ModifiedNNet = ModifiedBackpropagation(3, 4, 2)\n",
    "\n",
    "# Тестуємо модифіковану нейромережу\n",
    "max_iter = 2000\n",
    "learningRate = 0.01\n",
    "expectedError = 1e-3\n",
    "\n",
    "ModifiedNNet.Fit(trainingSet, labelSet, learningRate, max_iter, expectedError)\n",
    "\n",
    "# Перевірка подібності цільових значень із розрахунками модифікованої нейромоделі\n",
    "res = []\n",
    "for row in trainingSet:\n",
    "    res.append(ModifiedNNet.forwardPropagate(row).round(1).tolist())\n",
    "print('\\nExpected =\\n  ', labelSet, '\\nResult = \\n', res)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-11T14:33:42.439052400Z"
    }
   },
   "id": "96bb0d8a15af645c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Оригінальна нейромережа:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "852cc391c727f97e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Кількість прихованих нейронів: 2**\n",
    "- **Сума квадратів помилок після 2000 епох: приблизно 2.63**\n",
    "- **Результати для тренувального набору:**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "868692fe3eec6751"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Expected =\n",
    "[[1, 0], [1, 0], [1, 0], [0, 0], [0, 0], [0, 1], [0, 1], [0, 1]] \n",
    "Result = \n",
    "[[0.0, 0.0], [0.3, 0.0], [0.3, 0.0], [0.6, 0.1], [0.0, 0.3], [0.0, 0.8], [0.0, 0.8], [0.0, 1.1]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f127c8d82d9f794"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Модифікована нейромережа:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "896238526cf7bd57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **Кількість прихованих нейронів: 4**\n",
    "- **Сума квадратів помилок після 2000 епох: приблизно 2.80**\n",
    "- **Результати для тренувального набору:**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "853543b08a60aef7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Expected =\n",
    "[[1, 0], [1, 0], [1, 0], [0, 0], [0, 0], [0, 1], [0, 1], [0, 1]] \n",
    "Result = \n",
    "[[0.0, 0.0], [0.3, 0.1], [0.3, 0.1], [0.6, 0.2], [0.0, 0.6], [0.0, 0.8], [0.0, 0.8], [0.0, 0.9]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9d2f5b0f15bb87d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Висновки:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4625450c436e1b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. **Зміна кількості прихованих нейронів у модифікованій нейромережі відбулася з 2 до 4.**\n",
    "2. **Вартість помилок для обох моделей виглядає прийнятно, і обидві моделі вчаться.**\n",
    "3. **Оригінальна нейромережа має тенденцію навчатися трошки швидше (сума квадратів помилок після 2000 епох - близько 2.63), але модифікована нейромережа також ефективна (сума квадратів помилок - близько 2.80).**\n",
    "4. **У більш складних завданнях або з більшими обсягами даних кількість прихованих нейронів та параметри навчання можуть відігравати більшу роль у виборі оптимальної моделі.** "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb4e119c5b2b2e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
